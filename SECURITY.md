# Security Policy

## Educational Purpose

This repository contains educational material on adversarial attacks against neural networks for defensive security learning.

### Learning Objectives

This tutorial aims to:
- ✅ Teach fundamental concepts of adversarial machine learning
- ✅ Demonstrate CNN vulnerabilities through hands-on examples
- ✅ Provide practical implementation of FGSM attacks
- ✅ Educate on the gap between test accuracy and robustness
- ✅ Inspire defensive security research

All content is for authorized educational and research purposes.

## Authorized Use

✅ **Permitted:**
- Educational learning and skill development
- Academic research and citation
- Security testing of your own ML models
- Authorized penetration testing with permission
- Defensive security tool development
- Understanding adversarial robustness concepts

## Prohibited Use

❌ **Not Permitted:**
- Attacking production ML systems without authorization
- Bypassing security controls in deployed models
- Unauthorized testing of third-party systems
- Malicious exploitation of model vulnerabilities
- Weaponization for harmful purposes

## Responsible Research

When using this tutorial:

1. **Test Only Authorized Systems** - Only apply techniques to models you own or have permission to test
2. **Follow Ethical Guidelines** - Adhere to responsible disclosure practices
3. **Prioritize Defense** - Use knowledge to build robust systems, not attack others
4. **Comply with Terms** - Respect all applicable laws and terms of service

## Real-World Implications

This tutorial demonstrates attacks against MNIST digit classification. The same techniques apply to critical systems:

- Autonomous vehicles (misclassifying stop signs)
- Medical imaging (hiding malignant tumors)
- Facial recognition (bypassing authentication)
- Fraud detection (evading transaction monitoring)

Understanding these risks helps build better defenses.

## Reporting Security Issues

If you discover security issues in this tutorial or its code:

**Email:** scott@perfecxion.ai

Please include:
- Description of the issue
- Steps to reproduce
- Potential impact
- Suggested fixes

### Response Timeline

- **Initial Response:** Within 48 hours
- **Assessment:** Within 7 days
- **Resolution:** Based on severity

## Supported Versions

| Version | Supported          |
| ------- | ------------------ |
| main    | :white_check_mark: |

## Contact

- **Email:** scott@perfecxion.ai
- **Alternative:** scthornton@gmail.com

For questions about responsible use or defensive applications, contact scott@perfecxion.ai.
