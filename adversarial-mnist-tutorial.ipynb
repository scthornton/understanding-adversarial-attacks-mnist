{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Adversarial MNIST: Building Secure Deep Learning Models\n",
    "\n",
    "**Educational Walkthrough: CNN Architecture + Adversarial Robustness Testing**\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. **Build a CNN from scratch** using `torch.nn.Module`\n",
    "2. **Train and evaluate** a model on MNIST with proper data loading\n",
    "3. **Use forward hooks** to monitor model internals during inference\n",
    "4. **Generate adversarial examples** using the Fast Gradient Sign Method (FGSM)\n",
    "5. **Evaluate model robustness** against adversarial perturbations\n",
    "6. **Visualize vulnerabilities** to understand security implications\n",
    "\n",
    "---\n",
    "\n",
    "## Time Estimate: 2-3 hours\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This notebook requires the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install torch torchvision matplotlib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Setup and Imports\n",
    "\n",
    "Let's start by importing all the libraries we'll need throughout this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "MNIST CNN with adversarial robustness testing.\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Building a CNN from scratch\n",
    "2. Training on MNIST\n",
    "3. Using hooks to monitor activations\n",
    "4. Generating adversarial examples with FGSM\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Point:** These imports give you:\n",
    "\n",
    "- `torch.nn` - Neural network building blocks (layers, loss functions)\n",
    "- `torch.optim` - Optimization algorithms (SGD, Adam, etc.)\n",
    "- `torchvision` - Datasets and image transformations\n",
    "- `DataLoader` - Efficient batching, shuffling, and parallel data loading\n",
    "\n",
    "---\n",
    "\n",
    "# Part 2: Understanding the Architecture\n",
    "\n",
    "## What We're Building\n",
    "\n",
    "A simple Convolutional Neural Network (CNN) for MNIST digit classification.\n",
    "\n",
    "**Architecture Flow:**\n",
    "\n",
    "```\n",
    "Input (28×28 grayscale image)\n",
    "    ↓\n",
    "Conv2d (1 → 32 channels, 3×3 kernel)\n",
    "    ↓\n",
    "ReLU activation\n",
    "    ↓\n",
    "MaxPool2d (2×2) → spatial size halved\n",
    "    ↓\n",
    "Conv2d (32 → 64 channels, 3×3 kernel)\n",
    "    ↓\n",
    "ReLU activation\n",
    "    ↓\n",
    "MaxPool2d (2×2) → spatial size halved again\n",
    "    ↓\n",
    "Flatten → convert to 1D vector\n",
    "    ↓\n",
    "Linear (3136 → 128)\n",
    "    ↓\n",
    "ReLU activation\n",
    "    ↓\n",
    "Dropout (0.5) → prevent overfitting\n",
    "    ↓\n",
    "Linear (128 → 10) → output logits\n",
    "```\n",
    "\n",
    "## Build the CNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple CNN for MNIST classification.\n",
    "    \n",
    "    Architecture: Conv → ReLU → Pool → Conv → ReLU → Pool → FC → ReLU → Dropout → FC\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1,      # MNIST is grayscale (1 channel)\n",
    "            out_channels=32,    # Learn 32 different feature maps\n",
    "            kernel_size=3,      # 3×3 kernels\n",
    "            padding=1           # Keep spatial dimensions\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            padding=1\n",
    "        )\n",
    "        \n",
    "        # Pooling layer (will be reused)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        # After 2 pooling layers: 28 → 14 → 7\n",
    "        # So: 64 channels × 7 × 7 = 3136 features\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 digit classes (0-9)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, 1, 28, 28)\n",
    "        \n",
    "        Returns:\n",
    "            Logits of shape (batch_size, 10)\n",
    "        \"\"\"\n",
    "        # First conv block\n",
    "        x = self.conv1(x)           # (batch, 1, 28, 28) → (batch, 32, 28, 28)\n",
    "        x = F.relu(x)               # Activation\n",
    "        x = self.pool(x)            # (batch, 32, 28, 28) → (batch, 32, 14, 14)\n",
    "        \n",
    "        # Second conv block\n",
    "        x = self.conv2(x)           # (batch, 32, 14, 14) → (batch, 64, 14, 14)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)            # (batch, 64, 14, 14) → (batch, 64, 7, 7)\n",
    "        \n",
    "        # Flatten for fully connected layers\n",
    "        x = x.view(-1, 64 * 7 * 7)  # (batch, 64, 7, 7) → (batch, 3136)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)             # (batch, 3136) → (batch, 128)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)         # Random dropout during training\n",
    "        x = self.fc2(x)             # (batch, 128) → (batch, 10)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Learning Points:**\n",
    "\n",
    "- `nn.Module` - Base class for all neural networks in PyTorch\n",
    "- `super().__init__()` - Required to initialize the parent class\n",
    "- `self.conv1 = nn.Conv2d(...)` - Define layers in `__init__`\n",
    "- `forward()` method - Defines the computation graph\n",
    "- `F.relu()` - Functional API (no learnable parameters)\n",
    "- `x.view()` - Reshape tensors (similar to numpy's reshape)\n",
    "\n",
    "## Test the Model Architecture\n",
    "\n",
    "Before training, let's verify the architecture works with the expected input shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_architecture():\n",
    "    \"\"\"Verify the model architecture works with expected input shapes.\"\"\"\n",
    "    model = SimpleCNN()\n",
    "    \n",
    "    # Create a batch of 4 random MNIST images\n",
    "    batch_size = 4\n",
    "    x = torch.randn(batch_size, 1, 28, 28)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    \n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"Expected output shape: ({batch_size}, 10)\")\n",
    "    \n",
    "    assert output.shape == (batch_size, 10), \"Output shape mismatch!\"\n",
    "    print(\"✓ Model architecture test passed!\")\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Run the test\n",
    "test_model_architecture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "- Input shape: `torch.Size([4, 1, 28, 28])`\n",
    "- Output shape: `torch.Size([4, 10])`\n",
    "- Total parameters: ~400,000\n",
    "\n",
    "---\n",
    "\n",
    "# Part 3: Data Loading and Preprocessing\n",
    "\n",
    "PyTorch provides the `DataLoader` class for efficient data handling. Let's set up our MNIST data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(batch_size: int = 64, download: bool = True):\n",
    "    \"\"\"\n",
    "    Create training and test data loaders for MNIST.\n",
    "    \n",
    "    Args:\n",
    "        batch_size: Number of samples per batch\n",
    "        download: Whether to download MNIST if not present\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train_loader, test_loader)\n",
    "    \"\"\"\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),           # Convert PIL Image to tensor [0, 1]\n",
    "        transforms.Normalize(            # Normalize to mean=0, std=1\n",
    "            mean=(0.1307,),              # MNIST mean\n",
    "            std=(0.3081,)                # MNIST std\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # Download and load training data\n",
    "    train_dataset = datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=True,\n",
    "        download=download,\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    # Download and load test data\n",
    "    test_dataset = datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=False,\n",
    "        download=download,\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,          # Shuffle training data\n",
    "        num_workers=2          # Use 2 subprocesses for data loading\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,         # Don't shuffle test data\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Training batches: {len(train_loader)}\")\n",
    "    print(f\"Test batches: {len(test_loader)}\")\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Create data loaders\n",
    "train_loader, test_loader = get_data_loaders(batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Learning Points:**\n",
    "\n",
    "- `transforms.Compose()` - Chain multiple transformations\n",
    "- `transforms.Normalize()` - Standardize inputs (critical for training stability)\n",
    "- `DataLoader` - Handles batching, shuffling, and parallel loading\n",
    "- `shuffle=True` - Randomize training order (prevents overfitting to sequence)\n",
    "\n",
    "## Visualize Sample Data\n",
    "\n",
    "Let's look at some examples from the dataset to understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_batch(data_loader, num_samples: int = 8):\n",
    "    \"\"\"Display a few samples from the dataset.\"\"\"\n",
    "    # Get one batch\n",
    "    images, labels = next(iter(data_loader))\n",
    "    \n",
    "    # Create subplot grid\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Denormalize for visualization\n",
    "        img = images[i].squeeze()  # Remove channel dimension\n",
    "        img = img * 0.3081 + 0.1307  # Reverse normalization\n",
    "        \n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(f'Label: {labels[i].item()}', fontsize=14)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"✓ Visualization complete\")\n",
    "\n",
    "# Visualize training samples\n",
    "visualize_batch(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Training the Model\n",
    "\n",
    "Now we'll implement the training loop. This is where the model learns from the data.\n",
    "\n",
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    epoch: int\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \n",
    "    Returns:\n",
    "        Average loss for the epoch\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode (enables dropout)\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Move data to device (CPU or GPU)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        # Backward pass (compute gradients)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track statistics\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1)  # Get predicted class\n",
    "        correct += pred.eq(target).sum().item()\n",
    "        total += target.size(0)\n",
    "        \n",
    "        # Print progress every 100 batches\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch {epoch} [{batch_idx}/{len(train_loader)}] '\n",
    "                  f'Loss: {loss.item():.4f} '\n",
    "                  f'Acc: {100. * correct / total:.2f}%')\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    print(f'Epoch {epoch} Summary: '\n",
    "          f'Avg Loss: {avg_loss:.4f} '\n",
    "          f'Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Learning Points:**\n",
    "\n",
    "- `model.train()` - Enables dropout and batch norm training mode\n",
    "- `optimizer.zero_grad()` - **CRITICAL:** Clear gradients from previous iteration\n",
    "- `loss.backward()` - Compute gradients via backpropagation\n",
    "- `optimizer.step()` - Update weights using computed gradients\n",
    "- `.item()` - Extract Python scalar from tensor\n",
    "- `.to(device)` - Move tensors to GPU if available\n",
    "\n",
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    test_loader: DataLoader,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate model on test set.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (test_loss, test_accuracy)\n",
    "    \"\"\"\n",
    "    model.eval()  # Set to evaluation mode (disables dropout)\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # No gradient computation needed for evaluation\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            \n",
    "            # Sum up batch loss\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            \n",
    "            # Get predictions\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            total += target.size(0)\n",
    "    \n",
    "    test_loss /= total\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, '\n",
    "          f'Accuracy: {correct}/{total} ({accuracy:.2f}%)\\n')\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Learning Points:**\n",
    "\n",
    "- `model.eval()` - Disables dropout and batch norm updates\n",
    "- `with torch.no_grad()` - Disable gradient computation (saves memory)\n",
    "- `reduction='sum'` - Sum losses instead of averaging (we'll average manually)\n",
    "\n",
    "## Main Training Loop\n",
    "\n",
    "Now let's put it all together and train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs: int = 5, batch_size: int = 64, learning_rate: float = 0.001):\n",
    "    \"\"\"Main training pipeline.\"\"\"\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = SimpleCNN().to(device)\n",
    "    \n",
    "    # Create optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Get data loaders\n",
    "    train_loader, test_loader = get_data_loaders(batch_size=batch_size)\n",
    "    \n",
    "    # Training loop\n",
    "    train_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Train\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, device, epoch)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Evaluate\n",
    "        test_loss, test_acc = evaluate(model, test_loader, device)\n",
    "        test_accuracies.append(test_acc)\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), 'mnist_cnn.pth')\n",
    "    print(\"✓ Model saved to mnist_cnn.pth\")\n",
    "    \n",
    "    return model, train_losses, test_accuracies\n",
    "\n",
    "# Train the model\n",
    "model, train_losses, test_accuracies = train_model(epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Results:**\n",
    "- Epoch 1: ~96% accuracy\n",
    "- Epoch 5: >98% accuracy\n",
    "\n",
    "---\n",
    "\n",
    "# Part 5: Monitoring with Forward Hooks\n",
    "\n",
    "Forward hooks let us intercept and monitor activations during inference. This is useful for debugging and security analysis.\n",
    "\n",
    "## Activation Monitor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationMonitor:\n",
    "    \"\"\"Monitor activations during forward pass using hooks.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: nn.Module):\n",
    "        self.activations = {}\n",
    "        self.hooks = []\n",
    "        \n",
    "        # Register hooks on all ReLU layers\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, nn.ReLU):\n",
    "                hook = module.register_forward_hook(self._make_hook(name))\n",
    "                self.hooks.append(hook)\n",
    "    \n",
    "    def _make_hook(self, name: str):\n",
    "        \"\"\"Create a hook function that stores activations.\"\"\"\n",
    "        def hook(module, input, output):\n",
    "            # Store activation statistics\n",
    "            self.activations[name] = {\n",
    "                'mean': output.mean().item(),\n",
    "                'std': output.std().item(),\n",
    "                'max': output.max().item(),\n",
    "                'min': output.min().item(),\n",
    "                'shape': list(output.shape)\n",
    "            }\n",
    "        return hook\n",
    "    \n",
    "    def remove_hooks(self):\n",
    "        \"\"\"Clean up hooks.\"\"\"\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "    \n",
    "    def print_stats(self):\n",
    "        \"\"\"Print activation statistics.\"\"\"\n",
    "        print(\"\\n=== Activation Statistics ===\")\n",
    "        for name, stats in self.activations.items():\n",
    "            print(f\"{name}:\")\n",
    "            print(f\"  Shape: {stats['shape']}\")\n",
    "            print(f\"  Mean: {stats['mean']:.4f}, Std: {stats['std']:.4f}\")\n",
    "            print(f\"  Min: {stats['min']:.4f}, Max: {stats['max']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Learning Points:**\n",
    "\n",
    "- `register_forward_hook()` - Intercept forward pass\n",
    "- Hooks receive `(module, input, output)`\n",
    "- Useful for debugging and security monitoring\n",
    "- Always call `hook.remove()` when done\n",
    "\n",
    "## Test Activation Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_activation_monitoring():\n",
    "    \"\"\"Demonstrate activation monitoring with hooks.\"\"\"\n",
    "    device = torch.device(\"cpu\")  # Use CPU for simplicity\n",
    "    \n",
    "    # Load trained model\n",
    "    model = SimpleCNN().to(device)\n",
    "    model.load_state_dict(torch.load('mnist_cnn.pth'))\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a test batch\n",
    "    _, test_loader = get_data_loaders(batch_size=4)\n",
    "    images, labels = next(iter(test_loader))\n",
    "    images = images.to(device)\n",
    "    \n",
    "    # Create monitor\n",
    "    monitor = ActivationMonitor(model)\n",
    "    \n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        output = model(images)\n",
    "    \n",
    "    # Print statistics\n",
    "    monitor.print_stats()\n",
    "    \n",
    "    # Clean up\n",
    "    monitor.remove_hooks()\n",
    "\n",
    "# Run the test\n",
    "test_activation_monitoring()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: Adversarial Examples with FGSM\n",
    "\n",
    "**Fast Gradient Sign Method (FGSM)** is one of the simplest adversarial attacks. It adds a small perturbation in the direction that maximizes the loss.\n",
    "\n",
    "## Understanding FGSM\n",
    "\n",
    "The attack works by:\n",
    "1. Computing the gradient of the loss with respect to the input image\n",
    "2. Taking the sign of the gradient\n",
    "3. Adding a small epsilon-scaled perturbation in that direction\n",
    "\n",
    "**Formula:** `x_adversarial = x + ε × sign(∇_x Loss(x, y_true))`\n",
    "\n",
    "## FGSM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(\n",
    "    model: nn.Module,\n",
    "    images: torch.Tensor,\n",
    "    labels: torch.Tensor,\n",
    "    epsilon: float\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate adversarial examples using Fast Gradient Sign Method.\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network to attack\n",
    "        images: Clean images (batch)\n",
    "        labels: True labels\n",
    "        epsilon: Perturbation magnitude\n",
    "    \n",
    "    Returns:\n",
    "        Adversarial examples\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Require gradients for input\n",
    "    images.requires_grad = True\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = F.cross_entropy(outputs, labels)\n",
    "    \n",
    "    # Zero gradients\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # Backward pass to get gradients of input\n",
    "    loss.backward()\n",
    "    \n",
    "    # Collect gradient sign\n",
    "    gradient_sign = images.grad.sign()\n",
    "    \n",
    "    # Create adversarial example\n",
    "    adversarial = images + epsilon * gradient_sign\n",
    "    \n",
    "    # Clamp to valid image range\n",
    "    # Note: MNIST is normalized to mean=0.1307, std=0.3081\n",
    "    # So valid range in normalized space is approximately [-2, 2]\n",
    "    adversarial = torch.clamp(adversarial, -2, 2)\n",
    "    \n",
    "    return adversarial.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Learning Points:**\n",
    "\n",
    "- `images.requires_grad = True` - Enable gradient computation for input\n",
    "- `loss.backward()` - Computes gradients w.r.t. input\n",
    "- `sign()` - Direction of steepest ascent\n",
    "- `detach()` - Remove from computation graph\n",
    "\n",
    "## Test Adversarial Robustness\n",
    "\n",
    "Let's test how the model performs against different epsilon values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_adversarial_robustness(epsilon_values: List[float] = [0.0, 0.05, 0.1, 0.2, 0.3]):\n",
    "    \"\"\"Test model robustness against FGSM attacks.\"\"\"\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    # Load model\n",
    "    model = SimpleCNN().to(device)\n",
    "    model.load_state_dict(torch.load('mnist_cnn.pth'))\n",
    "    model.eval()\n",
    "    \n",
    "    # Get test data\n",
    "    _, test_loader = get_data_loaders(batch_size=1000)\n",
    "    images, labels = next(iter(test_loader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    print(\"\\n=== Adversarial Robustness Test ===\")\n",
    "    results = {}\n",
    "    \n",
    "    for epsilon in epsilon_values:\n",
    "        if epsilon == 0.0:\n",
    "            # Clean accuracy (no attack)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                predictions = outputs.argmax(dim=1)\n",
    "                accuracy = (predictions == labels).float().mean().item() * 100\n",
    "        else:\n",
    "            # Generate adversarial examples\n",
    "            adv_images = fgsm_attack(model, images, labels, epsilon)\n",
    "            \n",
    "            # Test on adversarial examples\n",
    "            with torch.no_grad():\n",
    "                outputs = model(adv_images)\n",
    "                predictions = outputs.argmax(dim=1)\n",
    "                accuracy = (predictions == labels).float().mean().item() * 100\n",
    "        \n",
    "        results[epsilon] = accuracy\n",
    "        print(f\"Epsilon: {epsilon:.2f} → Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run robustness test\n",
    "robustness_results = test_adversarial_robustness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Results:**\n",
    "```\n",
    "Epsilon: 0.00 → Accuracy: 98.45%\n",
    "Epsilon: 0.05 → Accuracy: 95.32%\n",
    "Epsilon: 0.10 → Accuracy: 82.14%\n",
    "Epsilon: 0.20 → Accuracy: 41.23%\n",
    "Epsilon: 0.30 → Accuracy: 18.67%\n",
    "```\n",
    "\n",
    "**Key Insight:** Even tiny perturbations (ε=0.1 ≈ 3% of pixel range) can dramatically reduce accuracy!\n",
    "\n",
    "## Visualize Adversarial Examples\n",
    "\n",
    "Let's visualize what these adversarial perturbations look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_adversarial_examples(epsilon: float = 0.1):\n",
    "    \"\"\"Visualize clean vs adversarial examples.\"\"\"\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    # Load model\n",
    "    model = SimpleCNN().to(device)\n",
    "    model.load_state_dict(torch.load('mnist_cnn.pth'))\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a few test samples\n",
    "    _, test_loader = get_data_loaders(batch_size=5)\n",
    "    images, labels = next(iter(test_loader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    # Generate adversarial examples\n",
    "    adv_images = fgsm_attack(model, images, labels, epsilon)\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        clean_outputs = model(images)\n",
    "        adv_outputs = model(adv_images)\n",
    "        clean_preds = clean_outputs.argmax(dim=1)\n",
    "        adv_preds = adv_outputs.argmax(dim=1)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "    \n",
    "    for i in range(5):\n",
    "        # Denormalize for visualization\n",
    "        clean_img = images[i].squeeze() * 0.3081 + 0.1307\n",
    "        adv_img = adv_images[i].squeeze() * 0.3081 + 0.1307\n",
    "        perturbation = (adv_img - clean_img) * 10  # Amplify for visibility\n",
    "        \n",
    "        # Clean image\n",
    "        axes[0, i].imshow(clean_img.cpu(), cmap='gray')\n",
    "        axes[0, i].set_title(f'Clean\\nPred: {clean_preds[i].item()}\\nTrue: {labels[i].item()}', fontsize=12)\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Perturbation\n",
    "        axes[1, i].imshow(perturbation.cpu(), cmap='seismic', vmin=-1, vmax=1)\n",
    "        axes[1, i].set_title(f'Perturbation\\n(ε={epsilon})', fontsize=12)\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # Adversarial image\n",
    "        axes[2, i].imshow(adv_img.cpu(), cmap='gray')\n",
    "        success = '✓' if adv_preds[i] != labels[i] else '✗'\n",
    "        axes[2, i].set_title(f'Adversarial {success}\\nPred: {adv_preds[i].item()}', fontsize=12)\n",
    "        axes[2, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(f\"✓ Adversarial visualization complete\")\n",
    "\n",
    "# Visualize adversarial examples\n",
    "visualize_adversarial_examples(epsilon=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 7: Security Analysis and Key Takeaways\n",
    "\n",
    "## What Did We Learn?\n",
    "\n",
    "### PyTorch Fundamentals\n",
    "\n",
    "1. **Model Building:**\n",
    "   - Subclass `nn.Module` for custom architectures\n",
    "   - Define layers in `__init__`, computation in `forward()`\n",
    "   - Use `model.train()` vs `model.eval()` for different modes\n",
    "\n",
    "2. **Training Loop:**\n",
    "   - Standard pattern: `zero_grad()` → `forward()` → `loss()` → `backward()` → `step()`\n",
    "   - Always use `with torch.no_grad()` for inference\n",
    "   - Move tensors to device with `.to(device)`\n",
    "\n",
    "3. **Hooks:**\n",
    "   - `register_forward_hook()` for monitoring activations\n",
    "   - Useful for debugging and security analysis\n",
    "   - Remember to remove hooks when done\n",
    "\n",
    "### Security Insights\n",
    "\n",
    "1. **Neural networks are surprisingly fragile**\n",
    "   - A 98% accurate model drops to 82% with ε=0.1 perturbation\n",
    "   - Perturbations are often invisible to humans\n",
    "\n",
    "2. **Adversarial robustness ≠ clean accuracy**\n",
    "   - High test accuracy doesn't mean the model is secure\n",
    "   - Always test robustness separately\n",
    "\n",
    "3. **Defense is non-trivial**\n",
    "   - Simple training doesn't produce robust models\n",
    "   - Need specialized techniques (adversarial training, certified defenses)\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. Always normalize inputs\n",
    "2. Use DataLoader for batching and shuffling\n",
    "3. Save checkpoints during training\n",
    "4. Test architecture before training\n",
    "5. Monitor activations for debugging\n",
    "6. **Test adversarial robustness before deployment**\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises for Further Learning\n",
    "\n",
    "**Beginner:**\n",
    "1. Add learning rate scheduling with `torch.optim.lr_scheduler.StepLR`\n",
    "2. Plot training curves (loss and accuracy over epochs)\n",
    "3. Try different batch sizes and observe the impact\n",
    "\n",
    "**Intermediate:**\n",
    "4. Add batch normalization after conv layers\n",
    "5. Compare SGD vs Adam vs AdamW optimizers\n",
    "6. Implement PGD attack (multi-step iterative FGSM)\n",
    "\n",
    "**Advanced:**\n",
    "7. Implement adversarial training (train on mix of clean and adversarial examples)\n",
    "8. Export model to ONNX format\n",
    "9. Create a robustness curve plotting accuracy vs epsilon\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "After mastering this notebook, you're ready for:\n",
    "\n",
    "1. **Transfer Learning:** Fine-tuning pretrained models (ResNet, ViT)\n",
    "2. **LLM Security:** Building a simple transformer and testing prompt injection\n",
    "3. **Model Export:** PyTorch → ONNX → TensorRT pipeline\n",
    "4. **Advanced Attacks:** PGD, C&W, adversarial patches\n",
    "5. **Defenses:** Adversarial training, defensive distillation, certified robustness\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "**RuntimeError: Expected tensor for argument #1 'indices' to have scalar type Long**\n",
    "- Solution: Ensure labels are `torch.long` type\n",
    "\n",
    "**CUDA out of memory**\n",
    "- Solution: Reduce batch size or use CPU\n",
    "\n",
    "**Model accuracy stuck at ~10%**\n",
    "- Solution: Check learning rate (try 0.001) and verify data normalization\n",
    "\n",
    "**Adversarial examples don't fool the model**\n",
    "- Solution: Increase epsilon value (try 0.2 or 0.3)\n",
    "\n",
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "**PyTorch Documentation:**\n",
    "- [Official Tutorials](https://pytorch.org/tutorials/)\n",
    "- [API Reference](https://pytorch.org/docs/stable/index.html)\n",
    "\n",
    "**Adversarial ML Research:**\n",
    "- [Explaining and Harnessing Adversarial Examples (FGSM Paper)](https://arxiv.org/abs/1412.6572)\n",
    "- [Towards Deep Learning Models Resistant to Adversarial Attacks (PGD)](https://arxiv.org/abs/1706.06083)\n",
    "- [RobustBench: Adversarial Robustness Benchmark](https://robustbench.github.io/)\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You've completed the PyTorch Adversarial MNIST tutorial. You now understand both how to build deep learning models and how to test their security properties."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
